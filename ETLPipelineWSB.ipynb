{
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3 (ipykernel)",
            "language": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2,
    "cells": [
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Assignment 2: MemeStox - Automated Data Pipeline for Meme Stock Analysis"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The world of stock trading has seen an unprecedented shift with online communities, like WallStreetBets on Reddit, playing a significant role in stock movements. This assignment dives into the automation of data extraction from both WallStreetBets and financial data sources, then integrates this data into a structured database using Python. \n",
                "\n",
                "**Objective**: Construct an ETL pipeline to gather, prepare, and integrate data related to the most-discussed stocks on WallStreetBets and their financial attributes.\n",
                "\n",
                "**Flow of the MemeStox ETL pipeline:**\n",
                "1. Database Setup: Create a database and tables to store the extracted data.\n",
                "2. Extract, Transform, Load for WallStreetBets\n",
                "3. Identify the most discussed tickers from the WallStreetBets data.\n",
                "4. Extract, Transform, Load for Financial Data\n",
                "5. Final execution: Run the ETL pipeline for a specific date range."
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**API Key**:\n",
                "\n",
                "To fetch the data, we will use two APIs: [Tradestie API](https://tradestie.com/apps/reddit/api/) and [Alpha Vantage API](https://www.alphavantage.co/documentation/). Tradestie API is a free API that provides data from WallStreetBets. **However, Alpha Vantage API for financial data requires an API key.** Alpha Vanatage provides us premium API key for this class, which you can find in your inbox. Use your API key to make calls to the API. Please do not share this key with anyone outside of the class."
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Comment lines:**\n",
                "\n",
                "Each cell starts with a comment line that indicates the type of the cell:\n",
                "\n",
                "- `### TEST FUNCTION`: This is where you will write your code. \n",
                "- `### SKIP`: This cell is provided for you to run the function and see the output.\n",
                "- `# DO NOT CHANGE THE CODE`: No need to change anything in this cell.\n",
                "\n",
                "Do not remove or change the comment lines as it will affect the grading of your assignment."
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**MemeStox Database ERD:**\n",
                "\n",
                "![width:500](img/WSBETS_ERD.png)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Before you start, run the following cell to import the required packages."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "# DO NOT CHANGE THE CODE\n",
                "\n",
                "import sqlite3\n",
                "import requests\n",
                "import pandas as pd"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Database Setup\n",
                "\n",
                "First, create a database connection to the SQLite database file `memestox.db` using the `sqlite3` library. We'll use this connection object to interact with the database."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "# DO NOT CHANGE THE CODE\n",
                "\n",
                "conn = sqlite3.connect('memestox.db')"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Write `create_table` function to initiate your database tables. The function takes three arguments: `conn`, `table_name`, and `schema`. The function drops the specified `table_name` if it exists, and creates a new `table` with the specified `schema`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "### TEST FUNCTION: test_create_table\n",
                "# DO NOT REMOVE THE LINE ABOVE\n",
                "\n",
                "def create_table(conn, table: str, schema: str):\n",
                "    \"\"\"Create a table with the given schema. If the table already exists, drop it and create a new one.\n",
                "    \n",
                "    Args:\n",
                "        conn (sqlite3.Connection): Connection to database\n",
                "        table (str): Table name\n",
                "        schema (str): Schema for the table. For example, \"(id INT, name TEXT)\"\n",
                "\n",
                "    Returns:\n",
                "        None\n",
                "\n",
                "    \"\"\"\n",
                "    try:\n",
                "        with conn:\n",
                "        # Drop the table if it exists\n",
                "            conn.execute(f\"DROP TABLE IF EXISTS {table};\")\n",
                "        # Create table\n",
                "            conn.execute(f\"CREATE TABLE {table} {schema};\")\n",
                "            \n",
                "      \n",
                "        # Commit\n",
                "        conn.commit()\n",
                "    except sqlite3.OperationalError as e:\n",
                "        print(f\"OperationalError: {e}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "### SKIP\n",
                "# Test your code here\n",
                "\n",
                "# **Update the schemas to match tables in the ERD**\n",
                "schema_posts = \"\"\"\n",
                "(\n",
                "    ticker VARCHAR(4),\n",
                "    date VARCHAR(10),\n",
                "    no_of_comments INT,\n",
                "    sentiment TEXT,\n",
                "    sentiment_score FLOAT,\n",
                "    PRIMARY KEY (ticker, date)\n",
                ")\n",
                "\"\"\"\n",
                "schema_stocks = \"\"\"\n",
                "(\n",
                "ticker varchar(4),\n",
                "date varchar(10),\n",
                "open float,\n",
                "high float,\n",
                "low float,\n",
                "close float,\n",
                "volume int,\n",
                "PRIMARY KEY (ticker, date)\n",
                "\n",
                ")\n",
                "\"\"\"\n",
                "schema_companies = \"\"\"\n",
                "(\n",
                "ticker varchar(4) PRIMARY KEY,\n",
                "name text, \n",
                "description text,\n",
                "sector text,\n",
                "industry text,\n",
                "country text,\n",
                "marketcap int,\n",
                "ebitda float,\n",
                "eps float,\n",
                "beta float\n",
                ")\n",
                "\"\"\"\n",
                "\n",
                "create_table(conn, 'posts', schema_posts)\n",
                "create_table(conn, 'stocks', schema_stocks)\n",
                "create_table(conn, 'companies', schema_companies)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Extract, Transform, Load (ETL) for WallStreetBets Reddit Posts\n",
                "\n",
                "**2-1: Extraction**\n",
                "\n",
                "The `extract_posts` function connects to the `tradestie` API to pull Reddit posts on WallStreetBets for a specific date. The function takes one argument: `date`, which is a string representing the date in the format \"YYYY-MM-DD\". The function retrieves the WSBets data for the specified `date` using the Tradestie API, and returns the data as a dictionary.\n",
                "\n",
                "See the [Tradestie API documentation](https://tradestie.com/apps/reddit/api/) for more information."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "### TEST FUNCTION: test_extract_posts\n",
                "# DO NOT REMOVE THE LINE ABOVE\n",
                "\n",
                "def extract_posts(date: str)-\u003edict:\n",
                "    \"\"\"Get wsbets reddit posts for a given date from tradestie api\n",
                "    \n",
                "    Args:\n",
                "        date (str): Date in the format \"YYYY-MM-DD\"\n",
                "\n",
                "    Returns:\n",
                "        dict: JSON response from the API\n",
                "    \n",
                "    \"\"\"\n",
                "\n",
                "    # Set url and params for the API request\n",
                "    # See the API documentation for more details\n",
                "    url = \"https://tradestie.com/api/v1/apps/reddit\"\n",
                "    params = {\n",
                "        \"date\" :date\n",
                "    }\n",
                "\n",
                "    # Make request and get response\n",
                "    response = requests.get(url, params = params)\n",
                "    \n",
                "    # Return json response\n",
                "    data = response.json()\n",
                "    return data \n",
                "  \n",
                "   "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "[{'no_of_comments': 91,\n  'sentiment': 'Bullish',\n  'sentiment_score': 0.046,\n  'ticker': 'TSLA'},\n {'no_of_comments': 33,\n  'sentiment': 'Bullish',\n  'sentiment_score': 0.015,\n  'ticker': 'AI'},\n {'no_of_comments': 25,\n  'sentiment': 'Bullish',\n  'sentiment_score': 0.164,\n  'ticker': 'NVDA'},\n {'no_of_comments': 20,\n  'sentiment': 'Bullish',\n  'sentiment_score': 0.09,\n  'ticker': 'QQQ'}]"
                    },
                    "execution_count": 6,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "### SKIP\n",
                "# Test your code here\n",
                "\n",
                "date = '2023-10-02'\n",
                "\n",
                "response_posts = extract_posts(date)\n",
                "response_posts[:4]\n",
                ""
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**2-2: Transformation**\n",
                "\n",
                "Once the data is fetched, use `transform_posts` to select the data we need from the response and format them correctly for insertion into your database. The function takes two arguments: `response`, and `date`. `response` is a list of dictionaries containing the WSBets data, and `date` is a string representing the date in the format \"YYYY-MM-DD\". "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [],
            "source": [
                "### TEST FUNCTION: test_transform_posts\n",
                "# DO NOT REMOVE THE LINE ABOVE\n",
                "\n",
                "def transform_posts(response: dict, date: str)-\u003elist:\n",
                "    \"\"\"Transform wsbets reddit post data into a list of tuple for data insertion\n",
                "    \n",
                "    Args:\n",
                "        response (dict): JSON response from the API\n",
                "        date (str): Date in the format \"YYYY-MM-DD\"\n",
                "\n",
                "    Returns:\n",
                "        list: List of tuples to be inserted into the database\n",
                "    \n",
                "    \"\"\"\n",
                "\n",
                "    # For each post in the response, extract the fields that match the table schema and store in a tuple\n",
                "    # Append them all in a list\n",
                "    data_posts = []\n",
                "    for item in response:\n",
                "        data_tuples = (\n",
                "            item.get(\"ticker\", \"N/A\"),\n",
                "            date,\n",
                "            item.get(\"no_of_comments\"),\n",
                "            item.get(\"sentiment\", \"N/A\"),\n",
                "            item.get(\"sentiment_score\"),\n",
                "        )\n",
                "        \n",
                "    # Return a list of tuples\n",
                "        data_posts.append(data_tuples)\n",
                "    return data_posts\n",
                ""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "[('TSLA', '2023-10-02', 91, 'Bullish', 0.046),\n ('AI', '2023-10-02', 33, 'Bullish', 0.015),\n ('NVDA', '2023-10-02', 25, 'Bullish', 0.164),\n ('QQQ', '2023-10-02', 20, 'Bullish', 0.09),\n ('RIVN', '2023-10-02', 15, 'Bullish', 0.092),\n ('AAPL', '2023-10-02', 14, 'Bearish', -0.253)]"
                    },
                    "execution_count": 8,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "### SKIP\n",
                "# Test your code here\n",
                "\n",
                "data_posts = transform_posts(response_posts, date)\n",
                "data_posts[:6]"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**2-3: Loading**\n",
                "\n",
                "The `load_data` function populates a table in your database with the transformed data. Like `create_table()`, this function is meant to be generic and can be used to load data into any table in your database that is specified by the `table_name` argument. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [],
            "source": [
                "### TEST FUNCTION: test_load_data\n",
                "# DO NOT REMOVE THE LINE ABOVE\n",
                "\n",
                "def load_data(conn, data: list, table: str):\n",
                "    \"\"\"Insert data into database\n",
                "    \n",
                "    Args:\n",
                "        conn (sqlite3.Connection): Connection to database\n",
                "        table (str): Table name\n",
                "        data (list): List of tuples to be inserted into the database\n",
                "\n",
                "    Returns:\n",
                "        None\n",
                "    \n",
                "    \"\"\"\n",
                "    if isinstance(data, str):\n",
                "        table, data = data, table\n",
                "    try:   \n",
                "        cursor = conn.cursor()\n",
                "\n",
                "        if table == 'stocks':\n",
                "            cursor.executemany ('''\n",
                "                INSERT OR IGNORE INTO stocks (ticker, date, open, high, low, close, volume)\n",
                "                VALUES(?,?,?,?,?,?,?)\n",
                "            ''', data)\n",
                "        elif table == 'companies':\n",
                "            cursor.executemany ('''\n",
                "                INSERT INTO companies (ticker, name, description, sector, industry, country, marketcap, ebitda, eps, beta)\n",
                "                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
                "            ''', data)\n",
                "        elif table == 'posts':\n",
                "            cursor.executemany('''\n",
                "                INSERT INTO posts (ticker, date, no_of_comments, sentiment, sentiment_score)\n",
                "                VALUES (?, ?, ?, ?, ?)\n",
                "            ''', data)\n",
                "        \n",
                "\n",
                "\n",
                "\n",
                "\n",
                "\n",
                "\n",
                "        conn.commit()\n",
                "        \n",
                "    except sqlite3.Error as e:\n",
                "        print(f\"An error occurred: {e}\")\n",
                "\n",
                "    \n",
                "    \n",
                "\n",
                "    ..."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "[('TSLA', '2023-10-02', 91, 'Bullish', 0.046),\n ('AI', '2023-10-02', 33, 'Bullish', 0.015),\n ('NVDA', '2023-10-02', 25, 'Bullish', 0.164),\n ('QQQ', '2023-10-02', 20, 'Bullish', 0.09),\n ('RIVN', '2023-10-02', 15, 'Bullish', 0.092),\n ('AAPL', '2023-10-02', 14, 'Bearish', -0.253),\n ('AMC', '2023-10-02', 13, 'Bullish', 0.095),\n ('TLT', '2023-10-02', 12, 'Bearish', -0.017)]"
                    },
                    "execution_count": 10,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "### SKIP\n",
                "# Test your code here\n",
                "\n",
                "load_data(conn, data_posts, 'posts')\n",
                "\n",
                "# verify data is inserted\n",
                "result = conn.execute(\"select * from posts limit 10;\").fetchall()\n",
                "result[:8]\n",
                ""
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**2-4: ETL Execution** \n",
                "\n",
                "Let's put it all together! Write the `posts_etl` function to coordinate the extraction, transformation, and loading of WallStreetBets data for a given date. It's a wrapper function that calls the `extract_posts()`, `transform_posts()`, and `load_data()` functions, with the date passed in as an argument."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [],
            "source": [
                "### TEST FUNCTION: test_posts_etl\n",
                "# DO NOT REMOVE THE LINE ABOVE\n",
                "\n",
                "def posts_etl(conn, date: str):\n",
                "    \"\"\"Extract, transform and load WallStreetBets data for a given date\n",
                "    \n",
                "    Args:\n",
                "        conn (sqlite3.Connection): Connection to database\n",
                "        date (str): Date in the format \"YYYY-MM-DD\"\n",
                "\n",
                "    Returns:\n",
                "        None\n",
                "    \n",
                "    \"\"\"\n",
                "    try:\n",
                "        # Extract data\n",
                "        posts_data = extract_posts(date)\n",
                "    \n",
                "        # Transform and load data if response is not empty\n",
                "        transformed_data = transform_posts(posts_data, date)\n",
                "        if not transformed_data:  \n",
                "            print(f\"No data to load after transformation for {date}\")\n",
                "            return\n",
                "    \n",
                "        load_data(conn, transformed_data, 'posts')\n",
                "        print(f\"ETL process completed for {date}\")\n",
                "    except sqlite3.OperationalError as e:\n",
                "        print(f\"OperationalError during ETL: {e}\")\n",
                "    finally:\n",
                "        conn.commit()\n",
                "\n",
                "    ...\n",
                ""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "ETL process completed for 2023-10-02\n"
                },
                {
                    "data": {
                        "text/plain": "[('TSLA', '2023-10-02', 91, 'Bullish', 0.046),\n ('AI', '2023-10-02', 33, 'Bullish', 0.015),\n ('NVDA', '2023-10-02', 25, 'Bullish', 0.164),\n ('QQQ', '2023-10-02', 20, 'Bullish', 0.09),\n ('RIVN', '2023-10-02', 15, 'Bullish', 0.092),\n ('AAPL', '2023-10-02', 14, 'Bearish', -0.253),\n ('AMC', '2023-10-02', 13, 'Bullish', 0.095)]"
                    },
                    "execution_count": 12,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "### SKIP\n",
                "# Test your code here\n",
                "\n",
                "# Recreate the table (create_table) to make sure no duplicate data is inserted\n",
                "create_table(conn, 'posts', schema_posts)\n",
                "\n",
                "# Run the ETL\n",
                "posts_etl(conn, date)\n",
                "\n",
                "# verify data is inserted\n",
                "result = conn.execute(\"select * from posts;\").fetchall()\n",
                "result[:7]\n",
                ""
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Identify the most discussed tickers from the WallStreetBets data.\n",
                "\n",
                "We now have a database table populated with WallStreetBets data. Next, write the `get_top_tickers` function to identify the most-discussed stocks from the populated `wsbets` table. These tickers serve as the input for the subsequent ETL tasks.\n",
                "\n",
                ""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [],
            "source": [
                "### TEST FUNCTION: test_get_top_tickers\n",
                "# DO NOT REMOVE THE LINE ABOVE\n",
                "\n",
                "def get_top_tickers(conn, n: int=10)-\u003elist:\n",
                "    \"\"\"Get top tickers from posts table\n",
                "    \n",
                "    Args:\n",
                "        conn (sqlite3.Connection): Connection to database\n",
                "        n (int): Number of top tickers to return. Default is 10.\n",
                "\n",
                "    Returns:\n",
                "        list: List of tickers\n",
                "    \n",
                "    \"\"\"\n",
                "\n",
                "    # Write a query to get the top tickers based on the number of comments\n",
                "    query = f\"\"\"\n",
                "    SELECT ticker, SUM(no_of_comments) AS total_comments\n",
                "    FROM posts\n",
                "    GROUP BY ticker\n",
                "    ORDER BY total_comments DESC\n",
                "    LIMIT {n};\n",
                "    \"\"\"\n",
                "    # Execute the query\n",
                "    cursor = conn.execute(query)\n",
                "    # Extract tickers from the query result. Append them in a list\n",
                "    tickers = [row[0] for row in cursor.fetchall()]\n",
                "\n",
                "    return tickers\n",
                "    \n",
                "    # Return list of tickers\n",
                ""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "['TSLA', 'AI', 'NVDA', 'QQQ', 'RIVN', 'AAPL', 'AMC', 'TLT', 'EOD', 'AMD']\n"
                }
            ],
            "source": [
                "### SKIP\n",
                "# Test your code here\n",
                "\n",
                "tickers = get_top_tickers(conn, 10)\n",
                "print(tickers)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Extract, Transform, Load (ETL) for Financial Data\n",
                "\n",
                "**4-1: Extraction**\n",
                "\n",
                "For each of the top tickers identified, employ the `extract_stocks` function to get **daily stock prices** and the `extract_companies` to obtain **company overview** from Alpha Vantage API. See the [Alpha Vantage documentation](https://www.alphavantage.co/documentation/) for more information.\n",
                "\n",
                "Both `extract_stocks` and `extract_companies` functions takes two arguments: `ticker` and `apikey`. `ticker` is a string representing the stock ticker symbol, an unique identifier for a company listed on the stock market. `apikey` is a string representing the API key for the Alpha Vantage API."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [],
            "source": [
                "### TEST FUNCTION: test_extract_stocks\n",
                "# DO NOT REMOVE THE LINE ABOVE\n",
                "\n",
                "def extract_stocks(ticker: str, key: str)-\u003edict:\n",
                "    \"\"\"Get stock data for a given ticker from Alpha Vantage API\n",
                "    \n",
                "    Args:\n",
                "        ticker (str): Stock ticker\n",
                "        key (str): Alpha Vantage API key\n",
                "\n",
                "    Returns:\n",
                "        dict: JSON response from the API\n",
                "    \n",
                "    \"\"\"\n",
                "\n",
                "    # Set url and params for the API request\n",
                "    # See the API documentation for more details\n",
                "    url = \"https://www.alphavantage.co/query\"\n",
                "    params = {\n",
                "        \"function\": \"TIME_SERIES_DAILY\",\n",
                "        \"apikey\": key,\n",
                "        \"symbol\": ticker\n",
                "    }\n",
                "\n",
                "    # Make request and get response\n",
                "    response = requests.get(url, params = params)\n",
                "    # Return json response\n",
                "    response = response.json()\n",
                "    return response"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "{'Meta Data': {'1. Information': 'Daily Prices (open, high, low, close) and Volumes', '2. Symbol': 'TSLA', '3. Last Refreshed': '2024-11-25', '4. Output Size': 'Compact', '5. Time Zone': 'US/Eastern'}, 'Time Series (Daily)': {'2024-11-25': {'1. open': '360.1400', '2. high': '361.9300', '3. low': '338.2000', '4. close': '338.5900', '5. volume': '95890899'}, '2024-11-22': {'1. open': '341.0850', '2. high': '361.5300', '3. low': '337.7000', '4. close': '352.5600', '5. volume': '89140722'}, '2024-11-21': {'1. open': '343.8100', '2. high': '347.9899', '3. low': '335.2800', '4. close': '339.6400', '5. volume': '58011719'}, '2024-11-20': {'1. open': '345.0000', '2. high': '346.5999', '3. low': '334.3000', '4. close': '342.0300', '5. volume': '66340650'}, '2024-11-19': {'1. open': '335.7600', '2. high': '347.3799', '3. low': '332.7500', '4. close': '346.0000', '5. volume': '88852452'}, '2024-11-18': {'1. open': '340.7300', '2. high': '348.5499', '3. low': '330.0100', '4. close': '338.7400', '5. volume': '126547455'}, '2024-11-15': {'1. open': '310.5700', '2. high': '324.6799', '3. low': '309.2200', '4. close': '320.7200', '5. volume': '114440286'}, '2024-11-14': {'1. open': '327.6900', '2. high': '329.9800', '3. low': '310.3700', '4. close': '311.1800', '5. volume': '120726109'}, '2024-11-13': {'1. open': '335.8500', '2. high': '344.5999', '3. low': '322.5000', '4. close': '330.2400', '5. volume': '125405599'}, '2024-11-12': {'1. open': '342.7400', '2. high': '345.8400', '3. low': '323.3100', '4. close': '328.4900', '5. volume': '155726016'}, '2024-11-11': {'1. open': '346.3000', '2. high': '358.6400', '3. low': '336.0000', '4. close': '350.0000', '5. volume': '210521625'}, '2024-11-08': {'1. open': '299.1400', '2. high': '328.7100', '3. low': '297.6600', '4. close': '321.2200', '5. volume': '204782763'}, '2024-11-07': {'1. open': '288.8900', '2. high': '299.7500', '3. low': '285.5200', '4. close': '296.9100', '5. volume': '117309232'}, '2024-11-06': {'1. open': '284.6700', '2. high': '289.5900', '3. low': '275.6200', '4. close': '288.5300', '5. volume': '165228710'}, '2024-11-05': {'1. open': '247.3400', '2. high': '255.2799', '3. low': '246.2101', '4. close': '251.4400', '5. volume': '69282505'}, '2024-11-04': {'1. open': '244.5600', '2. high': '248.9000', '3. low': '238.8800', '4. close': '242.8400', '5. volume': '68802354'}, '2024-11-01': {'1. open': '252.0430', '2. high': '254.0000', '3. low': '246.6300', '4. close': '248.9800', '5. volume': '57544757'}, '2024-10-31': {'1. open': '257.9900', '2. high': '259.7500', '3. low': '249.2500', '4. close': '249.8500', '5. volume': '66575292'}, '2024-10-30': {'1. open': '258.0350', '2. high': '263.3500', '3. low': '255.8201', '4. close': '257.5500', '5. volume': '53993576'}, '2024-10-29': {'1. open': '264.5100', '2. high': '264.9800', '3. low': '255.5100', '4. close': '259.5200', '5. volume': '80521751'}, '2024-10-28': {'1. open': '270.0000', '2. high': '273.5360', '3. low': '262.2400', '4. close': '262.5100', '5. volume': '107653603'}, '2024-10-25': {'1. open': '256.0100', '2. high': '269.4900', '3. low': '255.3200', '4. close': '269.1900', '5. volume': '161611931'}, '2024-10-24': {'1. open': '244.6800', '2. high': '262.1199', '3. low': '242.6500', '4. close': '260.4800', '5. volume': '204491903'}, '2024-10-23': {'1. open': '217.1250', '2. high': '218.7200', '3. low': '212.1100', '4. close': '213.6500', '5. volume': '80938892'}, '2024-10-22': {'1. open': '217.3100', '2. high': '218.2200', '3. low': '215.2600', '4. close': '217.9700', '5. volume': '43268741'}, '2024-10-21': {'1. open': '218.9000', '2. high': '220.4800', '3. low': '215.7260', '4. close': '218.8500', '5. volume': '47328988'}, '2024-10-18': {'1. open': '220.7100', '2. high': '222.2800', '3. low': '219.2300', '4. close': '220.7000', '5. volume': '49611867'}, '2024-10-17': {'1. open': '221.5900', '2. high': '222.0800', '3. low': '217.9000', '4. close': '220.8900', '5. volume': '50791784'}, '2024-10-16': {'1. open': '221.4000', '2. high': '222.8199', '3. low': '218.9300', '4. close': '221.3300', '5. volume': '49632824'}, '2024-10-15': {'1. open': '220.0100', '2. high': '224.2600', '3. low': '217.1200', '4. close': '219.5700', '5. volume': '62988787'}, '2024-10-14': {'1. open': '220.1300', '2. high': '221.9100', '3. low': '213.7400', '4. close': '219.1600', '5. volume': '86291923'}, '2024-10-11': {'1. open': '220.1300', '2. high': '223.3400', '3. low': '214.3800', '4. close': '217.8000', '5. volume': '142628874'}, '2024-10-10': {'1. open': '241.8100', '2. high': '242.7899', '3. low': '232.3400', '4. close': '238.7700', '5. volume': '83087063'}, '2024-10-09': {'1. open': '243.8200', '2. high': '247.4300', '3. low': '239.5100', '4. close': '241.0500', '5. volume': '66289529'}, '2024-10-08': {'1. open': '243.5600', '2. high': '246.2100', '3. low': '240.5600', '4. close': '244.5000', '5. volume': '56303160'}, '2024-10-07': {'1. open': '249.0000', '2. high': '249.8300', '3. low': '240.7000', '4. close': '240.8300', '5. volume': '68113270'}, '2024-10-04': {'1. open': '246.6900', '2. high': '250.9600', '3. low': '244.5800', '4. close': '250.0800', '5. volume': '86726285'}, '2024-10-03': {'1. open': '244.4800', '2. high': '249.7900', '3. low': '237.8100', '4. close': '240.6600', '5. volume': '80729240'}, '2024-10-02': {'1. open': '247.5500', '2. high': '251.1585', '3. low': '241.5000', '4. close': '249.0200', '5. volume': '93983930'}, '2024-10-01': {'1. open': '262.6700', '2. high': '263.9800', '3. low': '248.5300', '4. close': '258.0200', '5. volume': '87397613'}, '2024-09-30': {'1. open': '259.0400', '2. high': '264.8600', '3. low': '255.7700', '4. close': '261.6300', '5. volume': '80873381'}, '2024-09-27': {'1. open': '257.3750', '2. high': '260.6999', '3. low': '254.1200', '4. close': '260.4600', '5. volume': '70988067'}, '2024-09-26': {'1. open': '260.6000', '2. high': '261.7500', '3. low': '251.5300', '4. close': '254.2200', '5. volume': '67142193'}, '2024-09-25': {'1. open': '252.5400', '2. high': '257.0500', '3. low': '252.2800', '4. close': '257.0200', '5. volume': '65034318'}, '2024-09-24': {'1. open': '254.0800', '2. high': '257.1900', '3. low': '249.0501', '4. close': '254.2700', '5. volume': '88490999'}, '2024-09-23': {'1. open': '242.6100', '2. high': '250.0000', '3. low': '241.9200', '4. close': '250.0000', '5. volume': '86927194'}, '2024-09-20': {'1. open': '241.5200', '2. high': '243.9900', '3. low': '235.9200', '4. close': '238.2500', '5. volume': '99879070'}, '2024-09-19': {'1. open': '234.0000', '2. high': '244.2400', '3. low': '232.1300', '4. close': '243.9200', '5. volume': '102694576'}, '2024-09-18': {'1. open': '230.0900', '2. high': '235.6800', '3. low': '226.8800', '4. close': '227.2000', '5. volume': '78010204'}, '2024-09-17': {'1. open': '229.4500', '2. high': '234.5700', '3. low': '226.5533', '4. close': '227.8700', '5. volume': '66761636'}, '2024-09-16': {'1. open': '229.3000', '2. high': '229.9600', '3. low': '223.5300', '4. close': '226.7800', '5. volume': '54322995'}, '2024-09-13': {'1. open': '228.0000', '2. high': '232.6700', '3. low': '226.3200', '4. close': '230.2900', '5. volume': '59515114'}, '2024-09-12': {'1. open': '224.6600', '2. high': '231.4500', '3. low': '223.8300', '4. close': '229.8100', '5. volume': '72020042'}, '2024-09-11': {'1. open': '224.5500', '2. high': '228.4700', '3. low': '216.8003', '4. close': '228.1300', '5. volume': '83548633'}, '2024-09-10': {'1. open': '220.0700', '2. high': '226.4000', '3. low': '218.6377', '4. close': '226.1700', '5. volume': '78891136'}, '2024-09-09': {'1. open': '216.2000', '2. high': '219.8700', '3. low': '213.6700', '4. close': '216.2700', '5. volume': '67443518'}, '2024-09-06': {'1. open': '232.6000', '2. high': '233.6000', '3. low': '210.5100', '4. close': '210.7300', '5. volume': '112177004'}, '2024-09-05': {'1. open': '223.4900', '2. high': '235.0000', '3. low': '222.2500', '4. close': '230.1700', '5. volume': '119355013'}, '2024-09-04': {'1. open': '210.5900', '2. high': '222.2200', '3. low': '210.5700', '4. close': '219.4100', '5. volume': '80217329'}, '2024-09-03': {'1. open': '215.2600', '2. high': '219.9043', '3. low': '209.6400', '4. close': '210.6000', '5. volume': '76714222'}, '2024-08-30': {'1. open': '208.6300', '2. high': '214.5701', '3. low': '207.0300', '4. close': '214.1100', '5. volume': '63370608'}, '2024-08-29': {'1. open': '209.8000', '2. high': '214.8900', '3. low': '205.9700', '4. close': '206.2800', '5. volume': '62308818'}, '2024-08-28': {'1. open': '209.7200', '2. high': '211.8400', '3. low': '202.5900', '4. close': '205.7500', '5. volume': '64116350'}, '2024-08-27': {'1. open': '213.2500', '2. high': '215.6600', '3. low': '206.9400', '4. close': '209.2100', '5. volume': '62821390'}, '2024-08-26': {'1. open': '218.7500', '2. high': '219.0900', '3. low': '211.0100', '4. close': '213.2100', '5. volume': '59301187'}, '2024-08-23': {'1. open': '214.4550', '2. high': '221.4800', '3. low': '214.2100', '4. close': '220.3200', '5. volume': '81525207'}, '2024-08-22': {'1. open': '223.8200', '2. high': '224.8000', '3. low': '210.3200', '4. close': '210.6600', '5. volume': '79514482'}, '2024-08-21': {'1. open': '222.6700', '2. high': '224.6594', '3. low': '218.8600', '4. close': '223.2700', '5. volume': '70145964'}, '2024-08-20': {'1. open': '224.8800', '2. high': '228.2200', '3. low': '219.5600', '4. close': '221.1000', '5. volume': '74001182'}, '2024-08-19': {'1. open': '217.0700', '2. high': '222.9800', '3. low': '214.0900', '4. close': '222.7200', '5. volume': '76435222'}, '2024-08-16': {'1. open': '211.1500', '2. high': '219.8000', '3. low': '210.8000', '4. close': '216.1200', '5. volume': '88765122'}, '2024-08-15': {'1. open': '205.0200', '2. high': '215.8800', '3. low': '204.8200', '4. close': '214.1400', '5. volume': '89848530'}, '2024-08-14': {'1. open': '207.3900', '2. high': '208.4400', '3. low': '198.7500', '4. close': '201.3800', '5. volume': '70250014'}, '2024-08-13': {'1. open': '198.4700', '2. high': '208.4900', '3. low': '197.0600', '4. close': '207.8300', '5. volume': '76247387'}, '2024-08-12': {'1. open': '199.0200', '2. high': '199.2600', '3. low': '194.6700', '4. close': '197.4900', '5. volume': '64044903'}, '2024-08-09': {'1. open': '197.0500', '2. high': '200.8800', '3. low': '195.1100', '4. close': '200.0000', '5. volume': '58648274'}, '2024-08-08': {'1. open': '195.7000', '2. high': '200.7000', '3. low': '192.0400', '4. close': '198.8400', '5. volume': '65033874'}, '2024-08-07': {'1. open': '200.7700', '2. high': '203.4900', '3. low': '191.4800', '4. close': '191.7600', '5. volume': '71159778'}, '2024-08-06': {'1. open': '200.7500', '2. high': '202.9000', '3. low': '192.6700', '4. close': '200.6400', '5. volume': '73783942'}, '2024-08-05': {'1. open': '185.2200', '2. high': '203.8799', '3. low': '182.0000', '4. close': '198.8800', '5. volume': '100308836'}, '2024-08-02': {'1. open': '214.8800', '2. high': '216.1300', '3. low': '205.7800', '4. close': '207.6700', '5. volume': '82880120'}, '2024-08-01': {'1. open': '227.6900', '2. high': '231.8670', '3. low': '214.3328', '4. close': '216.8600', '5. volume': '83861898'}, '2024-07-31': {'1. open': '227.9000', '2. high': '234.6800', '3. low': '226.7875', '4. close': '232.0700', '5. volume': '67497011'}, '2024-07-30': {'1. open': '232.2500', '2. high': '232.4100', '3. low': '220.0000', '4. close': '222.6200', '5. volume': '100560334'}, '2024-07-29': {'1. open': '224.9000', '2. high': '234.2700', '3. low': '224.7000', '4. close': '232.1000', '5. volume': '129201789'}, '2024-07-26': {'1. open': '221.1900', '2. high': '222.2799', '3. low': '215.3300', '4. close': '219.8000', '5. volume': '94604145'}, '2024-07-25': {'1. open': '216.8000', '2. high': '226.0000', '3. low': '216.2310', '4. close': '220.2500', '5. volume': '100636466'}, '2024-07-24': {'1. open': '225.4200', '2. high': '225.9900', '3. low': '214.7100', '4. close': '215.9900', '5. volume': '167942939'}, '2024-07-23': {'1. open': '253.6000', '2. high': '255.7594', '3. low': '245.6300', '4. close': '246.3800', '5. volume': '111928192'}, '2024-07-22': {'1. open': '244.2100', '2. high': '253.2100', '3. low': '243.7500', '4. close': '251.5100', '5. volume': '101225430'}, '2024-07-19': {'1. open': '247.7900', '2. high': '249.4400', '3. low': '236.8300', '4. close': '239.2000', '5. volume': '87403903'}, '2024-07-18': {'1. open': '251.0900', '2. high': '257.1400', '3. low': '247.2000', '4. close': '249.2300', '5. volume': '110869037'}, '2024-07-17': {'1. open': '252.7300', '2. high': '258.4700', '3. low': '246.1820', '4. close': '248.5000', '5. volume': '115584810'}, '2024-07-16': {'1. open': '255.3100', '2. high': '258.6200', '3. low': '245.8001', '4. close': '256.5600', '5. volume': '126332470'}, '2024-07-15': {'1. open': '255.9700', '2. high': '265.6000', '3. low': '251.7300', '4. close': '252.6400', '5. volume': '146912920'}, '2024-07-12': {'1. open': '235.8000', '2. high': '251.8400', '3. low': '233.0912', '4. close': '248.2300', '5. volume': '155955773'}, '2024-07-11': {'1. open': '263.3000', '2. high': '271.0000', '3. low': '239.6500', '4. close': '241.0300', '5. volume': '221707273'}, '2024-07-10': {'1. open': '262.8000', '2. high': '267.5900', '3. low': '257.8600', '4. close': '263.2600', '5. volume': '128519430'}, '2024-07-09': {'1. open': '251.0000', '2. high': '265.6100', '3. low': '250.3000', '4. close': '262.3300', '5. volume': '160742516'}, '2024-07-08': {'1. open': '247.7100', '2. high': '259.4390', '3. low': '244.5700', '4. close': '252.9400', '5. volume': '157219580'}}}\n"
                }
            ],
            "source": [
                "### SKIP\n",
                "# Test your code here\n",
                "\n",
                "ticker = 'TSLA'\n",
                "key = ''
                "\n",
                "response_stocks = extract_stocks(ticker, key)\n",
                "print(response_stocks)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [],
            "source": [
                "### TEST FUNCTION: test_extract_companies\n",
                "# DO NOT REMOVE THE LINE ABOVE\n",
                "\n",
                "def extract_companies(ticker: str, key: str)-\u003edict:\n",
                "    \"\"\"Get company data for a given ticker from Alpha Vantage API\n",
                "    \n",
                "    Args:\n",
                "        ticker (str): Stock ticker\n",
                "        key (str): Alpha Vantage API key\n",
                "\n",
                "    Returns:\n",
                "        dict: JSON response from the API\n",
                "    \n",
                "    \"\"\"\n",
                "\n",
                "    # Set url and params for the API request\n",
                "    # See the API documentation for more details\n",
                "    url = \"https://www.alphavantage.co/query\"\n",
                "    params = {\n",
                "        \"function\": \"OVERVIEW\",\n",
                "        \"apikey\": key,\n",
                "        \"symbol\": ticker\n",
                "    }\n",
                "\n",
                "    # Make request and get response\n",
                "    response = requests.get(url, params= params)\n",
                "    \n",
                "    # Return json response\n",
                "    response = response.json()\n",
                "    return response\n",
                ""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "{'Symbol': 'TSLA', 'AssetType': 'Common Stock', 'Name': 'Tesla Inc', 'Description': \"Tesla, Inc. is an American electric vehicle and clean energy company based in Palo Alto, California. Tesla's current products include electric cars, battery energy storage from home to grid-scale, solar panels and solar roof tiles, as well as other related products and services. In 2020, Tesla had the highest sales in the plug-in and battery electric passenger car segments, capturing 16% of the plug-in market (which includes plug-in hybrids) and 23% of the battery-electric (purely electric) market. Through its subsidiary Tesla Energy, the company develops and is a major installer of solar photovoltaic energy generation systems in the United States. Tesla Energy is also one of the largest global suppliers of battery energy storage systems, with 3 GWh of battery storage supplied in 2020.\", 'CIK': '1318605', 'Exchange': 'NASDAQ', 'Currency': 'USD', 'Country': 'USA', 'Sector': 'MANUFACTURING', 'Industry': 'MOTOR VEHICLES \u0026 PASSENGER CAR BODIES', 'Address': '3500 DEER CREEK RD, PALO ALTO, CA, US', 'OfficialSite': 'https://www.tesla.com', 'FiscalYearEnd': 'December', 'LatestQuarter': '2024-09-30', 'MarketCapitalization': '1086894244000', 'EBITDA': '13244000000', 'PERatio': '92.26', 'PEGRatio': '10.05', 'BookValue': '21.81', 'DividendPerShare': 'None', 'DividendYield': 'None', 'EPS': '3.67', 'RevenuePerShareTTM': '30.46', 'ProfitMargin': '0.131', 'OperatingMarginTTM': '0.108', 'ReturnOnAssetsTTM': '0.0476', 'ReturnOnEquityTTM': '0.204', 'RevenueTTM': '97150001000', 'GrossProfitTTM': '20853000000', 'DilutedEPSTTM': '3.67', 'QuarterlyEarningsGrowthYOY': '0.17', 'QuarterlyRevenueGrowthYOY': '0.078', 'AnalystTargetPrice': '233.16', 'AnalystRatingStrongBuy': '6', 'AnalystRatingBuy': '12', 'AnalystRatingHold': '19', 'AnalystRatingSell': '7', 'AnalystRatingStrongSell': '4', 'TrailingPE': '92.26', 'ForwardPE': '105.26', 'PriceToSalesRatioTTM': '11.19', 'PriceToBookRatio': '16.18', 'EVToRevenue': '11.43', 'EVToEBITDA': '80.3', 'Beta': '2.295', '52WeekHigh': '361.93', '52WeekLow': '138.8', '50DayMovingAverage': '264.06', '200DayMovingAverage': '211.83', 'SharesOutstanding': '3210060000', 'DividendDate': 'None', 'ExDividendDate': 'None'}\n"
                }
            ],
            "source": [
                "### SKIP\n",
                "# Test your code here\n",
                "ticker = \"TSLA\"\n",
                "response_companies = extract_companies(ticker, key)\n",
                "print(response_companies)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**4-2: Transformation**\n",
                "\n",
                "`transform_stocks` and `transform_companies` functions select the data we need from the response and convert them into a list of tuples for insertion into the database."
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                ""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [],
            "source": [
                "### TEST FUNCTION: test_transform_stocks\n",
                "# DO NOT REMOVE THE LINE ABOVE\n",
                "\n",
                "def transform_stocks(response: dict, ticker: str = 'AAPL')-\u003elist:\n",
                "    \"\"\"Transform stock data into a list of tuple for data insertion\n",
                "\n",
                "    Args:\n",
                "        response (dict): JSON response for stock data from the API\n",
                "\n",
                "    Returns:\n",
                "        list: List of tuples to be inserted into the database\n",
                "    \n",
                "    \"\"\"\n",
                "\n",
                "    # For each date in the response, extract the fields that match the table schema and store in a tuple\n",
                "    stock_data = []\n",
                "    time_series = response.get(\"Time Series (Daily)\", {})\n",
                "    ticker = response.get(\"Meta Data\", {}).get(\"2. Symbol\")\n",
                "    for date, data in time_series.items():\n",
                "        data_tuple = (\n",
                "            ticker,\n",
                "            date,\n",
                "            (data[\"1. open\"]),\n",
                "            (data[\"2. high\"]),\n",
                "            (data[\"3. low\"]),\n",
                "            (data[\"4. close\"]),\n",
                "            (data[\"5. volume\"])\n",
                "    )\n",
                "        stock_data.append(data_tuple)\n",
                "\n",
                "    # Return a list of tuples\n",
                "    return stock_data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "[('TSLA',\n  '2024-11-25',\n  '360.1400',\n  '361.9300',\n  '338.2000',\n  '338.5900',\n  '95890899'),\n ('TSLA',\n  '2024-11-22',\n  '341.0850',\n  '361.5300',\n  '337.7000',\n  '352.5600',\n  '89140722')]"
                    },
                    "execution_count": 20,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "### SKIP\n",
                "# Test your code here\n",
                "data_stocks = transform_stocks(response_stocks, ticker)\n",
                "data_stocks[:2]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "metadata": {},
            "outputs": [],
            "source": [
                "### TEST FUNCTION: test_transform_companies\n",
                "# DO NOT REMOVE THE LINE ABOVE\n",
                "\n",
                "def transform_companies(response: dict, ticker: str = \"AAPL\")-\u003elist:\n",
                "    \"\"\"Transform company data into a list of tuple for data insertion\n",
                "\n",
                "    Args:\n",
                "        response (dict): JSON response for company data from the API\n",
                "\n",
                "    Returns:\n",
                "        list: List of tuples to be inserted into the database\n",
                "    \n",
                "    \"\"\"\n",
                "\n",
                "    # Extract the fields that match the table schema and store in a tuple\n",
                "    data_tuple = (\n",
                "        response.get(\"Symbol\"),\n",
                "        response.get(\"Name\"),\n",
                "        response.get(\"Description\"),\n",
                "        response.get(\"Sector\"),\n",
                "        response.get(\"Industry\"),\n",
                "        response.get(\"Country\"),\n",
                "        response.get(\"MarketCapitalization\"),\n",
                "        response.get(\"EBITDA\"),\n",
                "        response.get(\"EPS\"),\n",
                "        response.get(\"Beta\")\n",
                "    )\n",
                "\n",
                "    # Return a list of tuples\n",
                "    return [data_tuple]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "[('TSLA',\n  'Tesla Inc',\n  \"Tesla, Inc. is an American electric vehicle and clean energy company based in Palo Alto, California. Tesla's current products include electric cars, battery energy storage from home to grid-scale, solar panels and solar roof tiles, as well as other related products and services. In 2020, Tesla had the highest sales in the plug-in and battery electric passenger car segments, capturing 16% of the plug-in market (which includes plug-in hybrids) and 23% of the battery-electric (purely electric) market. Through its subsidiary Tesla Energy, the company develops and is a major installer of solar photovoltaic energy generation systems in the United States. Tesla Energy is also one of the largest global suppliers of battery energy storage systems, with 3 GWh of battery storage supplied in 2020.\",\n  'MANUFACTURING',\n  'MOTOR VEHICLES \u0026 PASSENGER CAR BODIES',\n  'USA',\n  '1086894244000',\n  '13244000000',\n  '3.67',\n  '2.295')]"
                    },
                    "execution_count": 22,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "### SKIP\n",
                "# Test your code here\n",
                "\n",
                "data_companies = transform_companies(response_companies, ticker)\n",
                "data_companies[:]"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**4-3: Loading**\n",
                "\n",
                "We can insert the transformed data into the corresponding tables (`stocks` and `companies`) using the `load_data` function defined earlier."
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**4-4: ETL Execution**\n",
                "\n",
                "Write a wrapper function `stocks_etl` that call the `extract_stocks()`, `transform_stocks()`, and `load_data()` functions, with the ticker and API key passed in as arguments. Similarily, `companies_etl` is a wrapper functions that call the `extract_companies()`, `transform_companies()`, and `load_data()` functions, with the ticker and API key passed in as arguments.\n",
                ""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "metadata": {},
            "outputs": [],
            "source": [
                "### TEST FUNCTION: test_stocks_etl\n",
                "# DO NOT REMOVE THE LINE ABOVE\n",
                "\n",
                "def stocks_etl(conn, ticker: str, key:str):\n",
                "    \"\"\"Extract, transform and load stock data for a given ticker\n",
                "\n",
                "    Args:\n",
                "        conn (sqlite3.Connection): Connection to database\n",
                "        ticker (str): Stock ticker\n",
                "        key (str): Alpha Vantage API key\n",
                "\n",
                "    Returns:\n",
                "        None\n",
                "    \n",
                "    \"\"\"\n",
                "\n",
                "    # Extract data\n",
                "    \n",
                "    response = extract_stocks(ticker, key)\n",
                "    \n",
                "\n",
                "    # Transform and load data if response is not empty\n",
                "    if response and \"Time Series (Daily)\" in response:\n",
                "        transformed_data = transform_stocks(response, ticker)\n",
                "        \n",
                "        load_data(conn, transformed_data, 'stocks')\n",
                "    else:\n",
                "        print(\"No valid 'Time Series (Daily) data in response\")\n",
                "\n",
                ""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Inserted Data: [('TSLA', '2024-11-25', 360.14, 361.93, 338.2, 338.59, 95890899), ('TSLA', '2024-11-22', 341.085, 361.53, 337.7, 352.56, 89140722)]\n"
                }
            ],
            "source": [
                "### SKIP\n",
                "# Test your code here\n",
                "\n",
                "# Recreate the table (create_table) to make sure no duplicate data is inserted\n",
                "create_table(conn, 'stocks', schema_stocks)\n",
                "\n",
                "# Run the ETL\n",
                "stocks_etl(conn, ticker, key)\n",
                "\n",
                "# verify data is inserted\n",
                "result = conn.execute(\"select * from stocks;\").fetchall()\n",
                "print(\"Inserted Data:\", result[:2])\n",
                ""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "metadata": {},
            "outputs": [],
            "source": [
                "### TEST FUNCTION: test_companies_etl\n",
                "# DO NOT REMOVE THE LINE ABOVE\n",
                "\n",
                "def companies_etl(conn, ticker: str, key:str):\n",
                "    \"\"\"Extract, transform and load company data for a given ticker\n",
                "\n",
                "    Args:\n",
                "        conn (sqlite3.Connection): Connection to database\n",
                "        ticker (str): Stock ticker\n",
                "        key (str): Alpha Vantage API key\n",
                "    \n",
                "    Returns:\n",
                "        None\n",
                "        \n",
                "    \"\"\"\n",
                "\n",
                "    # Extract data\n",
                "    response = extract_companies(ticker, key)\n",
                "    \n",
                "    # Transform and load data if response is not empty\n",
                "    if response:\n",
                "        transformed_data = transform_companies(response, ticker)\n",
                "        load_data(conn, transformed_data, 'companies')\n",
                "        "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 26,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "[('TSLA',\n  'Tesla Inc',\n  \"Tesla, Inc. is an American electric vehicle and clean energy company based in Palo Alto, California. Tesla's current products include electric cars, battery energy storage from home to grid-scale, solar panels and solar roof tiles, as well as other related products and services. In 2020, Tesla had the highest sales in the plug-in and battery electric passenger car segments, capturing 16% of the plug-in market (which includes plug-in hybrids) and 23% of the battery-electric (purely electric) market. Through its subsidiary Tesla Energy, the company develops and is a major installer of solar photovoltaic energy generation systems in the United States. Tesla Energy is also one of the largest global suppliers of battery energy storage systems, with 3 GWh of battery storage supplied in 2020.\",\n  'MANUFACTURING',\n  'MOTOR VEHICLES \u0026 PASSENGER CAR BODIES',\n  'USA',\n  1086894244000,\n  13244000000.0,\n  3.67,\n  2.295)]"
                    },
                    "execution_count": 26,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "### SKIP\n",
                "# Test your code here\n",
                "\n",
                "# Recreate the table (create_table) to make sure no duplicate data is inserted\n",
                "create_table(conn, 'companies', schema_companies)\n",
                "\n",
                "# Run the ETL\n",
                "companies_etl(conn, ticker, key)\n",
                "\n",
                "# verify data is inserted\n",
                "result = conn.execute(\"select * from companies\").fetchall()\n",
                "result[:2]"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "All the component parts are ready now. Let's move onto the final execution of the ETL pipeline where we automate the process of extracting, transforming, and loading the data for a specific date range. Before we do that, let's close the database connection we've used so far to avoid any issues. We'll create a new connection object later."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 27,
            "metadata": {},
            "outputs": [],
            "source": [
                "### SKIP\n",
                "# Test your code here\n",
                "\n",
                "conn.close()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Final Execution\n",
                "\n",
                "You've completed the ETL pipeline for MemeStox! Now, let's automate the process of extracting, transforming, and loading the data for a specific date range. \n",
                "\n",
                "First, update the below schemas to match the tables in the provided ERD. You can copy and paste the schemas from the earlier cell where you created the tables.\n",
                ""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 28,
            "metadata": {},
            "outputs": [],
            "source": [
                "### SKIP\n",
                "# Test your code here\n",
                "\n",
                "# Table schemas\n",
                "# 0. Update the schemas to match the tables in the ERD\n",
                "schema_posts = \"\"\" (\n",
                "    ticker VARCHAR(4),\n",
                "    date VARCHAR(10),\n",
                "    no_of_comments INT,\n",
                "    sentiment TEXT,\n",
                "    sentiment_score FLOAT,\n",
                "    PRIMARY KEY (ticker, date)\n",
                ")\n",
                "\"\"\"\n",
                "schema_stocks = \"\"\" (\n",
                "    ticker VARCHAR(4),\n",
                "        date VARCHAR(10),\n",
                "        open FLOAT,\n",
                "        high FLOAT,\n",
                "        low FLOAT,\n",
                "        close FLOAT,\n",
                "        volume INT,\n",
                "        PRIMARY KEY (ticker, date)\n",
                "        )\n",
                "\"\"\"\n",
                "schema_companies = \"\"\" (\n",
                "    ticker VARCHAR(4) PRIMARY KEY,\n",
                "    name TEXT,\n",
                "    description TEXT,\n",
                "    sector TEXT,\n",
                "    industry TEXT,\n",
                "    country TEXT,\n",
                "    marketcap INT,\n",
                "    ebitda FLOAT,\n",
                "    eps FLOAT,\n",
                "    beta FLOAT\n",
                "    )\n",
                "\n",
                "\"\"\""
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Let's set up the database with these updated schemas. Create a new connection object to the database file `memestox.db` and call the `create_table()` function for each of the tables."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 29,
            "metadata": {},
            "outputs": [],
            "source": [
                "### SKIP\n",
                "# Test your code here\n",
                "\n",
                "# 1. Connect to database\n",
                "conn = sqlite3.connect('memestox.db')\n",
                "\n",
                "# 2. Create tables (This will drop the tables created in the previous run)\n",
                "#create_table(conn, \"posts\", schema_posts)\n",
                "#create_table(conn, \"stocks\", schema_stocks)\n",
                "#create_table(conn, \"companies\", schema_companies)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Next, we need to specify a range of dates for which we want to extract the data. We'll use the today's date as the end date and the date 30 days ago as the start date. `gen_bdate_range()` below is to produce the list. You don't need to change the code, but verify that the list contains the correct dates."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 30,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "['2024-10-03', '2024-10-04', '2024-10-07', '2024-10-08', '2024-10-09', '2024-10-10', '2024-10-11', '2024-10-14', '2024-10-15', '2024-10-16', '2024-10-17', '2024-10-18', '2024-10-21', '2024-10-22', '2024-10-23', '2024-10-24', '2024-10-25', '2024-10-28', '2024-10-29', '2024-10-30', '2024-10-31', '2024-11-01', '2024-11-04', '2024-11-05', '2024-11-06', '2024-11-07', '2024-11-08', '2024-11-11', '2024-11-12', '2024-11-13']\n"
                }
            ],
            "source": [
                "# DO NOT CHANGE THE CODE\n",
                "\n",
                "# 3. Get business date range\n",
                "def gen_bdate_range(days, end_date: str)-\u003elist:\n",
                "    \"\"\"Generate business date range. days is the number of days to go back from end_date\n",
                "    \n",
                "    Args:\n",
                "        days (int): Number of days to go back\n",
                "        end_date (str): End date in the format \"YYYY-MM-DD\"\n",
                "\n",
                "    Returns:\n",
                "        list: List of business dates\n",
                "    \n",
                "    \"\"\"\n",
                "\n",
                "    return pd.bdate_range(end=end_date, periods=days).strftime(\"%Y-%m-%d\").tolist()\n",
                "\n",
                "# Replace today with the current date\n",
                "today = \"2024-11-13\"\n",
                "dates = gen_bdate_range(30, today)\n",
                "print(dates)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 31,
            "metadata": {},
            "outputs": [],
            "source": [
                "### SKIP\n",
                "# Test your code here\n",
                "\n",
                "# 4. Run posts_etl for each date in dates\n",
                "\n",
                "# 5. Get top 10 tickers from WallStreetBets data\n",
                "\n",
                "# 6. Run ETL for daily stock price and company overview for each ticker in the top tickers list\n",
                ""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 32,
            "metadata": {},
            "outputs": [],
            "source": [
                "### SKIP\n",
                "# Test your code here\n",
                "\n",
                "# 7a. Verify data in posts\n",
                ""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 33,
            "metadata": {},
            "outputs": [],
            "source": [
                "### SKIP\n",
                "# Test your code here\n",
                "\n",
                "# 7b. Verify data in stocks \n",
                ""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 34,
            "metadata": {},
            "outputs": [],
            "source": [
                "### SKIP\n",
                "# Test your code here\n",
                "\n",
                "# 7c. Verify data in companies\n",
                ""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 35,
            "metadata": {},
            "outputs": [],
            "source": [
                "### SKIP\n",
                "# Test your code here\n",
                "\n",
                "# 8. Close database connection\n",
                ""
            ]
        }
    ]
}
